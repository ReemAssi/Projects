{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN Encoder-Decoder model with attention that can translate English text to Arabic, given one file that contains English and its translated Arabic text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyvqGj-PPIAP"
   },
   "source": [
    "# Importing Required Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "5z4lk7CPMbpm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Flatten,LSTM, Bidirectional,Concatenate , dot ,Activation, Concatenate,Dot\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZ9k8izhPP4c"
   },
   "source": [
    "# Reading Data and converting it to DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "DN6RIxR_SK0a"
   },
   "outputs": [],
   "source": [
    "English = []\n",
    "Arabic = []\n",
    "with open('/content/ara_eng.txt', 'r',encoding='utf-8') as file:\n",
    "     lines = file.read().split(\"\\n\")[:-1]\n",
    "     for line in lines:\n",
    "       English.append(line.split(\"\\t\")[0])\n",
    "       Arabic.append(line.split(\"\\t\")[1])\n",
    "\n",
    "data = {\"English\": English, \"Arabic\": Arabic}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.iloc[0:10000]\n",
    "df[\"Arabic\"] = \"<start>\" + df[\"Arabic\"] + \"<end>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCdEwqogP1TX"
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "zSggTfMTSWXI"
   },
   "outputs": [],
   "source": [
    "English_Tokenizer = Tokenizer()\n",
    "English_Tokenizer.fit_on_texts(df['English'])\n",
    "English_Encoded = English_Tokenizer.texts_to_sequences(df['English'])\n",
    "\n",
    "Arabic_Tokenizer = Tokenizer()\n",
    "Arabic_Tokenizer.fit_on_texts(df['Arabic'])\n",
    "Arabic_Encoded = Arabic_Tokenizer.texts_to_sequences(df['Arabic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXkI4Nl4RE0w"
   },
   "source": [
    "# Extracting Vocab size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "MD180PrRUgju"
   },
   "outputs": [],
   "source": [
    "English_Vocab_Size = len(English_Tokenizer.word_counts)+1\n",
    "Arabic_Vocab_Size = len(Arabic_Tokenizer.word_counts)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWjhOgvDRO_-"
   },
   "source": [
    "#Extracting Maximum Sequence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "pOk9MHhaUwYc"
   },
   "outputs": [],
   "source": [
    "\n",
    "Arabic_Seq_Len = 0\n",
    "for i in range(len(Arabic_Encoded)):\n",
    "  if len(Arabic_Encoded[i]) > Arabic_Seq_Len:\n",
    "    Arabic_Seq_Len= len(Arabic_Encoded[i])\n",
    "English_Seq_Len = Arabic_Seq_Len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdHr_zNgRViB"
   },
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "EvFPJJ6qdit7"
   },
   "outputs": [],
   "source": [
    "\n",
    "English_Padding = pad_sequences(English_Encoded, maxlen=Arabic_Seq_Len, padding='post')\n",
    "Arabic_Padding = pad_sequences(Arabic_Encoded, maxlen=English_Seq_Len, padding='post')\n",
    "\n",
    "English_Padding= np.array(English_Padding)\n",
    "Arabic_Padding= np.array(Arabic_Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlZWvirGRd9j"
   },
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "iOfFp8rueFLJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(English_Padding, Arabic_Padding, test_size=0.1, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XSdn3bAR2qY"
   },
   "source": [
    "# Encoder Model with Bidirectional LSTM and Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "GfmzuKa4evBF"
   },
   "outputs": [],
   "source": [
    "Encoder_Input = Input(shape=(English_Seq_Len,)) \n",
    "Encoder_Embedding = Embedding(English_Vocab_Size, 128)(Encoder_Input)\n",
    "\n",
    "Encoder_BiLstm = Bidirectional(LSTM(256, return_sequences=True, return_state=True))\n",
    "Encoder_Result = Encoder_BiLstm(Encoder_Embedding)\n",
    "Encoder_Output = Encoder_Result[0]\n",
    "S1 = Concatenate()([Encoder_Result[1], Encoder_Result[3]])\n",
    "S2 = Concatenate()([Encoder_Result[2], Encoder_Result[4]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dB80fNarSZqI"
   },
   "source": [
    "# Decoder Model with LSTM and Initial State Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "IA8hdROFhP5s"
   },
   "outputs": [],
   "source": [
    "Decoder_Input = Input(shape=(Arabic_Seq_Len,)) \n",
    "Decoder_Embedding = Embedding(Arabic_Vocab_Size, 128)(Decoder_Input) \n",
    "\n",
    "\n",
    "Decoder_Lstm = LSTM(512, return_sequences=True, return_state=True) \n",
    "Decoder_Result = Decoder_Lstm(Decoder_Embedding, initial_state=[S1,S2])\n",
    "Decoder_Output = Decoder_Result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxoCCZGPSlF8"
   },
   "source": [
    "# Attention Mechanism in Decoder Model for Sequence-to-Sequence Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "7fYnc0iVlKst"
   },
   "outputs": [],
   "source": [
    "attention = Dense(1, activation='tanh')(Encoder_Output)\n",
    "attention = Activation('softmax')(attention)\n",
    "\n",
    "context = Concatenate(axis=2)([Encoder_Output, attention])\n",
    "context = Dense(512)(context)\n",
    "\n",
    "Decoder_Output = Concatenate(axis=-1)([context, Decoder_Output])\n",
    "\n",
    "decoder_dense = Dense(Arabic_Vocab_Size, activation=\"softmax\")\n",
    "Decoder_Output = decoder_dense(Decoder_Output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETeKeOWCS1Xb"
   },
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "n_DUdVMkpKs0"
   },
   "outputs": [],
   "source": [
    "model = Model([Encoder_Input, Decoder_Input], Decoder_Output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2yXuMUYBpc5e",
    "outputId": "7f9bb0e9-a03e-4a12-e7ab-36bfa2bc3780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 16)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 16, 128)      464768      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  [(None, 16, 512),   788480      ['embedding_2[0][0]']            \n",
      " )                               (None, 256),                                                     \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 16, 1)        513         ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 16, 1)        0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 16)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 16, 513)      0           ['bidirectional_1[0][0]',        \n",
      "                                                                  'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 16, 128)      1346816     ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 512)          0           ['bidirectional_1[0][1]',        \n",
      "                                                                  'bidirectional_1[0][3]']        \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 512)          0           ['bidirectional_1[0][2]',        \n",
      "                                                                  'bidirectional_1[0][4]']        \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 16, 512)      263168      ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, 16, 512),    1312768     ['embedding_3[0][0]',            \n",
      "                                 (None, 512),                     'concatenate_4[0][0]',          \n",
      "                                 (None, 512)]                     'concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 16, 1024)     0           ['dense_4[0][0]',                \n",
      "                                                                  'lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 16, 10522)    10785050    ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,961,563\n",
      "Trainable params: 14,961,563\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V5C6CI9S9Mf"
   },
   "source": [
    "# Model Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "eDDaNJO_syZm"
   },
   "outputs": [],
   "source": [
    "encoder_input_data = X_train\n",
    "decoder_input_data = y_train\n",
    "decoder_target_data =  y_train\n",
    "\n",
    "encoder_input_test = X_test\n",
    "decoder_input_test = y_test\n",
    "decoder_target_test=  y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ExvyILTl6oIB"
   },
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = ModelCheckpoint(\"give Your path to save check points\", monitor='val_accuracy')\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U5OMNa-4pk1F",
    "outputId": "925e32f6-2fa8-4b0b-a4fe-471fdd6cfa86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - ETA: 0s - loss: 0.9488 - accuracy: 0.8799"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "71/71 [==============================] - 341s 5s/step - loss: 0.9488 - accuracy: 0.8799 - val_loss: 0.9191 - val_accuracy: 0.8922\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.4589 - accuracy: 0.9285"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "71/71 [==============================] - 330s 5s/step - loss: 0.4589 - accuracy: 0.9285 - val_loss: 0.8259 - val_accuracy: 0.9103\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1945 - accuracy: 0.9647"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "71/71 [==============================] - 332s 5s/step - loss: 0.1945 - accuracy: 0.9647 - val_loss: 0.8374 - val_accuracy: 0.9172\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "71/71 [==============================] - 330s 5s/step - loss: 0.0778 - accuracy: 0.9846 - val_loss: 0.8355 - val_accuracy: 0.9178\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9912"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "71/71 [==============================] - 338s 5s/step - loss: 0.0445 - accuracy: 0.9912 - val_loss: 0.8413 - val_accuracy: 0.9197\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9951"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "71/71 [==============================] - 337s 5s/step - loss: 0.0257 - accuracy: 0.9951 - val_loss: 0.8067 - val_accuracy: 0.9214\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9968"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "71/71 [==============================] - 333s 5s/step - loss: 0.0168 - accuracy: 0.9968 - val_loss: 0.7968 - val_accuracy: 0.9244\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "71/71 [==============================] - 348s 5s/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.7867 - val_accuracy: 0.9234\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9993"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "71/71 [==============================] - 333s 5s/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.7272 - val_accuracy: 0.9264\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9997"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "71/71 [==============================] - 338s 5s/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.7189 - val_accuracy: 0.9259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f02d2b74a90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(\n",
    "    optimizer=RMSprop(lr=0.01),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    validation_data = ([encoder_input_test, decoder_input_test],decoder_target_test),\n",
    "                    callbacks= callbacks_list)\n",
    "\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_KfPC5vTNrz"
   },
   "source": [
    "# Sentence Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oqwua9OiA3KT",
    "outputId": "de5e75b1-0824-46e4-9386-1b65b2dee0d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The English sentence is Tom looks pale.\n",
      "The Arabic sentence is:  <start>يبدو توم شاحب الوجه.<end>\n",
      "The predicted Arabic sentence is:\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "start يبدو توم شاحب الوجه end          \n"
     ]
    }
   ],
   "source": [
    "def logits_to_sentence(logits, tokenizer):\n",
    "    index_to_words = {idx: word for word, idx in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = ''\n",
    "    \n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    predicted_words = [index_to_words[prediction] for prediction in predictions]\n",
    "    predicted_sentence = ' '.join(predicted_words)\n",
    "    \n",
    "    return predicted_sentence\n",
    "\n",
    "\n",
    "# Example sentence translation\n",
    "index = 1000\n",
    "print(\"The English sentence is\",df['English'][index])\n",
    "print(\"The Arabic sentence is: \",df['Arabic'][index])\n",
    "print('The predicted Arabic sentence is:')\n",
    "predicted_sentence = logits_to_sentence(\n",
    "    model.predict([English_Padding[index:index + 1], Arabic_Padding[index:index + 1]])[0],\n",
    "    Arabic_Tokenizer)\n",
    "print(predicted_sentence)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
